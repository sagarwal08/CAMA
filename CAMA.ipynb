{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D , BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "xtrain, ytrain = next(idg.flow_from_directory(train,\n",
    "                                            target_size=(256, 128),\n",
    "                                            color_mode='rgb',\n",
    "                                            batch_size=30000,\n",
    "                                            shuffle=True) )\n",
    "\n",
    "xtest, ytest = next(idg.flow_from_directory(test,\n",
    "                                            target_size=(256, 128),\n",
    "                                            color_mode='rgb',\n",
    "                                            batch_size=30000,\n",
    "                                            shuffle=True) )\n",
    "\n",
    "xquery, yquery = next(idg.flow_from_directory(query,\n",
    "                                            target_size=(256, 128),\n",
    "                                            color_mode='rgb',\n",
    "                                            batch_size=30000,\n",
    "                                            shuffle=True) )\n",
    "\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)\n",
    "print(xquery.shape)\n",
    "print(yquery.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the number of classes in your training dataset\n",
    "u = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(s1,s2,s3,m1,m2,m3, y_train):\n",
    "    \"\"\"Your custom loss function.\"\"\"\n",
    "    \n",
    "    s1 = tf.math.reduce_sum(s1*y_train, axis = 1)\n",
    "    s2 = tf.math.reduce_sum(s2*y_train, axis = 1)\n",
    "    s3 = tf.math.reduce_sum(s3*y_train, axis = 1)\n",
    "    \n",
    "    Li = -tf.math.log(s1*s2*s3)\n",
    "    \n",
    "    y = np.reshape(np.stack([y_train]*32, axis=1), (y_train.shape[0], 8, 4, y_train.shape[1]))\n",
    "    \n",
    "    p1 = tf.math.reduce_sum(m1*y, axis=-1)\n",
    "    p2 = tf.math.reduce_sum(m2*y, axis=-1)\n",
    "    p3 = tf.math.reduce_sum(m3*y, axis=-1)\n",
    "    \n",
    "    sigma1 = tf.sort(tf.reshape(p1,(y_train.shape[0],32)))[:,20]\n",
    "    sigma2 = tf.sort(tf.reshape(p2,(y_train.shape[0],32)))[:,20]\n",
    "    sigma3 = tf.sort(tf.reshape(p3,(y_train.shape[0],32)))[:,20]\n",
    "    \n",
    "    sigma1 = tf.reshape(tf.stack([sigma1]*32, axis=1), (y_train.shape[0],8,4))\n",
    "    sigma2 = tf.reshape(tf.stack([sigma2]*32, axis=1), (y_train.shape[0],8,4))\n",
    "    sigma3 = tf.reshape(tf.stack([sigma3]*32, axis=1), (y_train.shape[0],8,4))\n",
    "\n",
    "    a1 = 1 / (1 + tf.math.exp(-p1 + sigma1))\n",
    "    a2 = 1 / (1 + tf.math.exp(-p2 + sigma2))\n",
    "    a3 = 1 / (1 + tf.math.exp(-p3 + sigma3))\n",
    "    \n",
    "    a = a1*a2*a3\n",
    "    \n",
    "    Loap = tf.math.reduce_mean(a, axis=(1,2))\n",
    "    \n",
    "    loss = Li+Loap\n",
    "\n",
    "    return Loap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = keras.applications.ResNet50\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,unit, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Define some layers\n",
    "        self.unit = unit\n",
    "        self.resnet = resnet(include_top=False, weights='imagenet', input_shape=(256,128,3))\n",
    "        self.F = BatchNormalization()\n",
    "\n",
    "        #751 is the no. of classes in training set\n",
    "        self.m1 = Conv2D(self.unit, (1, 1), padding=\"same\")\n",
    "        self.m2 = Conv2D(self.unit, (1, 1), padding=\"same\")\n",
    "        self.m3 = Conv2D(self.unit, (1, 1), padding=\"same\")\n",
    "\n",
    "        self.s1 = keras.layers.GlobalAveragePooling2D()\n",
    "        self.s2 = keras.layers.GlobalAveragePooling2D()\n",
    "        self.s3 = keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "        self.S1 = keras.layers.Softmax()\n",
    "        self.S2 = keras.layers.Softmax()\n",
    "        self.S3 = keras.layers.Softmax()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.resnet(inputs)\n",
    "        F = self.F(x)\n",
    "        \n",
    "        m1 = self.m1(F)\n",
    "        m2 = self.m2(F)\n",
    "        m3 = self.m3(F)\n",
    "        \n",
    "        s1 = self.s1(m1)\n",
    "        s2 = self.s2(m2)\n",
    "        s3 = self.s3(m3)\n",
    "        \n",
    "        S1 = self.S1(s1)\n",
    "        S2 = self.S2(s2)\n",
    "        S3 = self.S3(s3)\n",
    "\n",
    "        # Add the loss to the model\n",
    "        loss = custom_loss(S1,S2,S3,m1,m2,m3, ytrain)\n",
    "        self.add_loss(loss)\n",
    "        return (S1+S2+S3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(unit = uint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False\n",
    "model.compile(optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xtrain, ytrain, ytrain.shape[0], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = True\n",
    "model.compile(optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xtrain, ytrain, ytrain.shape[0], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
